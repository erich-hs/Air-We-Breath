{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, shutil, warnings\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/raw/Vancouver/PM25/PM25_2018.csv',\n",
       " 'data/raw/Vancouver/PM25/PM25_2020.csv',\n",
       " 'data/raw/Vancouver/PM25/PM25_2019.csv',\n",
       " 'data/raw/Vancouver/PM25/PM25_2017.csv',\n",
       " 'data/raw/Vancouver/PM25/PM25_2021.csv',\n",
       " 'data/raw/Vancouver/PM25/PM25_2016.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading original datasets\n",
    "paths = glob(\"data/raw/Vancouver/PM25/*.csv\")\n",
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PM25_2016', 'PM25_2017', 'PM25_2018', 'PM25_2019', 'PM25_2020', 'PM25_2021']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading datasets\n",
    "datasets = {}\n",
    "for path in paths:\n",
    "    datasets[str(path[24:-4])] = pd.read_csv(path)\n",
    "\n",
    "datasets_list = sorted(list(datasets.keys()))\n",
    "datasets_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PM25_2016 dim: (529763, 14)\n",
      "PM25_2017 dim: (606525, 14)\n",
      "PM25_2018 dim: (557717, 14)\n",
      "PM25_2019 dim: (566637, 14)\n",
      "PM25_2020 dim: (564130, 14)\n",
      "PM25_2021 dim: (869059, 11)\n"
     ]
    }
   ],
   "source": [
    "# Dataset dimensions\n",
    "for dataset in datasets_list:\n",
    "    print(f\"{dataset} dim: {datasets[dataset].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary statistics for PM25_2016\n",
      "+----+-------------------+-----------+-----------+--------+---------+--------+\n",
      "|    | Variable          |   Uniques | Missing   | Min    | Max     | Mean   |\n",
      "|----+-------------------+-----------+-----------+--------+---------+--------|\n",
      "|  0 | DATE_PST          |      8784 | -         | -      | -       | -      |\n",
      "|  1 | DATE              |       366 | -         | -      | -       | -      |\n",
      "|  2 | TIME              |        24 | -         | -      | -       | -      |\n",
      "|  3 | STATION_NAME      |        63 | -         | -      | -       | -      |\n",
      "|  4 | STATION_NAME_FULL |        63 | -         | -      | -       | -      |\n",
      "|  5 | EMS_ID            |        63 | -         | -      | -       | -      |\n",
      "|  6 | NAPS_ID           |        39 | -         | -      | -       | -      |\n",
      "|  7 | RAW_VALUE         |    298200 | 6.06 %    | -0.137 | 605.228 | 5.508  |\n",
      "|  8 | ROUNDED_VALUE     |      1020 | 6.06 %    | -0.1   | 605.2   | 5.508  |\n",
      "|  9 | UNIT              |         1 | -         | -      | -       | -      |\n",
      "| 10 | INSTRUMENT        |         5 | -         | -      | -       | -      |\n",
      "| 11 | PARAMETER         |         1 | -         | -      | -       | -      |\n",
      "| 12 | OWNER             |         3 | -         | -      | -       | -      |\n",
      "| 13 | REGION            |         7 | -         | -      | -       | -      |\n",
      "+----+-------------------+-----------+-----------+--------+---------+--------+\n",
      "\n",
      "Summary statistics for PM25_2017\n",
      "+----+-------------------+-----------+-----------+--------+--------+--------+\n",
      "|    | Variable          |   Uniques | Missing   | Min    | Max    | Mean   |\n",
      "|----+-------------------+-----------+-----------+--------+--------+--------|\n",
      "|  0 | DATE_PST          |      8760 | -         | -      | -      | -      |\n",
      "|  1 | DATE              |       365 | -         | -      | -      | -      |\n",
      "|  2 | TIME              |        24 | -         | -      | -      | -      |\n",
      "|  3 | STATION_NAME      |        71 | -         | -      | -      | -      |\n",
      "|  4 | STATION_NAME_FULL |        71 | -         | -      | -      | -      |\n",
      "|  5 | EMS_ID            |        71 | -         | -      | -      | -      |\n",
      "|  6 | NAPS_ID           |        38 | -         | -      | -      | -      |\n",
      "|  7 | RAW_VALUE         |    327640 | 10.73 %   | -0.046 | 1432.5 | 8.006  |\n",
      "|  8 | ROUNDED_VALUE     |      2083 | 10.73 %   | 0.0    | 1432.5 | 8.006  |\n",
      "|  9 | UNIT              |         1 | -         | -      | -      | -      |\n",
      "| 10 | INSTRUMENT        |         5 | -         | -      | -      | -      |\n",
      "| 11 | PARAMETER         |         1 | -         | -      | -      | -      |\n",
      "| 12 | OWNER             |         5 | -         | -      | -      | -      |\n",
      "| 13 | REGION            |         7 | -         | -      | -      | -      |\n",
      "+----+-------------------+-----------+-----------+--------+--------+--------+\n",
      "\n",
      "Summary statistics for PM25_2018\n",
      "+----+-------------------+-----------+-----------+--------+----------+--------+\n",
      "|    | Variable          |   Uniques | Missing   | Min    | Max      | Mean   |\n",
      "|----+-------------------+-----------+-----------+--------+----------+--------|\n",
      "|  0 | DATE_PST          |      8760 | -         | -      | -        | -      |\n",
      "|  1 | DATE              |       365 | -         | -      | -        | -      |\n",
      "|  2 | TIME              |        24 | -         | -      | -        | -      |\n",
      "|  3 | STATION_NAME      |        68 | -         | -      | -        | -      |\n",
      "|  4 | STATION_NAME_FULL |        68 | -         | -      | -        | -      |\n",
      "|  5 | EMS_ID            |        68 | -         | -      | -        | -      |\n",
      "|  6 | NAPS_ID           |        39 | -         | -      | -        | -      |\n",
      "|  7 | RAW_VALUE         |    320744 | 6.84 %    | -0.029 | 1695.854 | 8.887  |\n",
      "|  8 | ROUNDED_VALUE     |      2591 | 6.84 %    | 0.0    | 1695.9   | 8.887  |\n",
      "|  9 | UNIT              |         1 | -         | -      | -        | -      |\n",
      "| 10 | INSTRUMENT        |         5 | -         | -      | -        | -      |\n",
      "| 11 | PARAMETER         |         1 | -         | -      | -        | -      |\n",
      "| 12 | OWNER             |         4 | -         | -      | -        | -      |\n",
      "| 13 | REGION            |         7 | -         | -      | -        | -      |\n",
      "+----+-------------------+-----------+-----------+--------+----------+--------+\n",
      "\n",
      "Summary statistics for PM25_2019\n",
      "+----+-------------------+-----------+-----------+--------+----------+--------+\n",
      "|    | Variable          |   Uniques | Missing   | Min    | Max      | Mean   |\n",
      "|----+-------------------+-----------+-----------+--------+----------+--------|\n",
      "|  0 | DATE_PST          |      8760 | -         | -      | -        | -      |\n",
      "|  1 | DATE              |       365 | -         | -      | -        | -      |\n",
      "|  2 | TIME              |        24 | -         | -      | -        | -      |\n",
      "|  3 | STATION_NAME      |        66 | -         | -      | -        | -      |\n",
      "|  4 | STATION_NAME_FULL |        66 | -         | -      | -        | -      |\n",
      "|  5 | EMS_ID            |        66 | -         | -      | -        | -      |\n",
      "|  6 | NAPS_ID           |        38 | -         | -      | -        | -      |\n",
      "|  7 | RAW_VALUE         |    321623 | 6.90 %    | -0.049 | 1085.288 | 6.144  |\n",
      "|  8 | ROUNDED_VALUE     |      1002 | 6.90 %    | 0.0    | 1085.3   | 6.144  |\n",
      "|  9 | UNIT              |         1 | -         | -      | -        | -      |\n",
      "| 10 | INSTRUMENT        |         5 | -         | -      | -        | -      |\n",
      "| 11 | PARAMETER         |         1 | -         | -      | -        | -      |\n",
      "| 12 | OWNER             |         5 | -         | -      | -        | -      |\n",
      "| 13 | REGION            |         7 | -         | -      | -        | -      |\n",
      "+----+-------------------+-----------+-----------+--------+----------+--------+\n",
      "\n",
      "Summary statistics for PM25_2020\n",
      "+----+-------------------+-----------+-----------+--------+---------+--------+\n",
      "|    | Variable          |   Uniques | Missing   | Min    | Max     | Mean   |\n",
      "|----+-------------------+-----------+-----------+--------+---------+--------|\n",
      "|  0 | DATE_PST          |      8784 | -         | -      | -       | -      |\n",
      "|  1 | DATE              |       366 | -         | -      | -       | -      |\n",
      "|  2 | TIME              |        24 | -         | -      | -       | -      |\n",
      "|  3 | STATION_NAME      |        64 | -         | -      | -       | -      |\n",
      "|  4 | STATION_NAME_FULL |        64 | -         | -      | -       | -      |\n",
      "|  5 | EMS_ID            |        64 | -         | -      | -       | -      |\n",
      "|  6 | NAPS_ID           |        37 | -         | -      | -       | -      |\n",
      "|  7 | RAW_VALUE         |    336755 | 4.77 %    | -0.042 | 541.159 | 6.636  |\n",
      "|  8 | ROUNDED_VALUE     |      2134 | 4.77 %    | 0.0    | 541.2   | 6.636  |\n",
      "|  9 | UNIT              |         1 | -         | -      | -       | -      |\n",
      "| 10 | INSTRUMENT        |         5 | -         | -      | -       | -      |\n",
      "| 11 | PARAMETER         |         1 | -         | -      | -       | -      |\n",
      "| 12 | OWNER             |         5 | -         | -      | -       | -      |\n",
      "| 13 | REGION            |         7 | -         | -      | -       | -      |\n",
      "+----+-------------------+-----------+-----------+--------+---------+--------+\n",
      "\n",
      "Summary statistics for PM25_2021\n",
      "+----+---------------+-----------+-----------+----------+----------+----------+\n",
      "|    | Variable      |   Uniques | Missing   | Min      | Max      | Mean     |\n",
      "|----+---------------+-----------+-----------+----------+----------+----------|\n",
      "|  0 | DATE_PST      |     13166 | -         | -        | -        | -        |\n",
      "|  1 | STATION_NAME  |        69 | -         | -        | -        | -        |\n",
      "|  2 | EMS_ID        |        69 | -         | -        | -        | -        |\n",
      "|  3 | NAPS_ID       |        40 | -         | -        | -        | -        |\n",
      "|  4 | PARAMETER     |         1 | -         | -        | -        | -        |\n",
      "|  5 | INSTRUMENT    |         4 | -         | -        | -        | -        |\n",
      "|  6 | RAW_VALUE     |    510206 | 3.75 %    | -0.634   | 2174.439 | 5.97     |\n",
      "|  7 | UNIT          |         1 | -         | -        | -        | -        |\n",
      "|  8 | ROUNDED_VALUE |      2154 | 3.75 %    | -0.6     | 2174.4   | 5.97     |\n",
      "|  9 | LATITUDE      |        69 | -         | 48.424   | 56.245   | 50.954   |\n",
      "| 10 | LONGITUDE     |        69 | -         | -130.352 | -114.888 | -122.954 |\n",
      "+----+---------------+-----------+-----------+----------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Summary statistics\n",
    "for dataset in datasets_list:\n",
    "    print(f\"Summary statistics for {dataset}\")\n",
    "    summary_df = {}\n",
    "    summary_df[\"Variable\"] = []\n",
    "    summary_df[\"Uniques\"] = []\n",
    "    summary_df[\"Missing\"] = []\n",
    "    summary_df[\"Min\"] = []\n",
    "    summary_df[\"Max\"] = []\n",
    "    summary_df[\"Mean\"] = []\n",
    "\n",
    "    for column in datasets[dataset].columns:\n",
    "        summary_df[\"Variable\"].append(column)\n",
    "        uniques = len(pd.unique(datasets[dataset][column]))\n",
    "        summary_df[\"Uniques\"].append(uniques)\n",
    "        missing = sum(datasets[dataset][column].isna())\n",
    "        missing_pct = missing / datasets[dataset].shape[0] * 100\n",
    "        if missing:\n",
    "            summary_df[\"Missing\"].append(f\"{missing_pct:.2f} %\")\n",
    "        else:\n",
    "            summary_df[\"Missing\"].append(\"-\")\n",
    "        if (\n",
    "            datasets[dataset][column].values.dtype in [\"float64\", \"int64\"]\n",
    "            and \"ID\" not in column\n",
    "        ):\n",
    "            summary_df[\"Min\"].append(round(datasets[dataset][column].min(), 3))\n",
    "            summary_df[\"Max\"].append(round(datasets[dataset][column].max(), 3))\n",
    "            summary_df[\"Mean\"].append(round(datasets[dataset][column].mean(), 3))\n",
    "        else:\n",
    "            summary_df[\"Min\"].append(\"-\")\n",
    "            summary_df[\"Max\"].append(\"-\")\n",
    "            summary_df[\"Mean\"].append(\"-\")\n",
    "\n",
    "    print(tabulate(pd.DataFrame(summary_df), headers=\"keys\", tablefmt=\"psql\") + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique stations: 87\n"
     ]
    }
   ],
   "source": [
    "# Unique stations\n",
    "stations = []\n",
    "for dataset in datasets_list:\n",
    "    for station in pd.unique(datasets[dataset][\"STATION_NAME\"]):\n",
    "        if station not in stations:\n",
    "            stations.append(station)\n",
    "\n",
    "print(f\"Total unique stations: {len(stations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique regions: 7\n"
     ]
    }
   ],
   "source": [
    "# Unique regions\n",
    "regions = []\n",
    "for dataset in datasets_list:\n",
    "    try:\n",
    "        for region in pd.unique(datasets[dataset][\"REGION\"]):\n",
    "            if region not in regions:\n",
    "                regions.append(region)\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "print(f\"Total unique regions: {len(regions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique stations per region\n",
      "+------------------------+--------+--------+--------+--------+--------+\n",
      "| REGION                 |   2016 |   2017 |   2018 |   2019 |   2020 |\n",
      "|------------------------+--------+--------+--------+--------+--------|\n",
      "| 01 - Vancouver Island  |     11 |     12 |     13 |     11 |     11 |\n",
      "| 02 - Lower Mainland    |     27 |     27 |     27 |     25 |     25 |\n",
      "| 03 - Southern Interior |      5 |      5 |      5 |      7 |      3 |\n",
      "| 04 - Kootenay          |      3 |      4 |      4 |      4 |      4 |\n",
      "| 05 - Cariboo           |      2 |      2 |      2 |      2 |      3 |\n",
      "| 06 - Skeena            |     10 |     10 |      8 |      9 |      9 |\n",
      "| 07 - Omineca-Peace     |      5 |     11 |      9 |      8 |      9 |\n",
      "+------------------------+--------+--------+--------+--------+--------+\n"
     ]
    }
   ],
   "source": [
    "# Unique stations per region\n",
    "stations_per_region = {}\n",
    "print(\"Unique stations per region\")\n",
    "for dataset in datasets_list:\n",
    "    try:\n",
    "        stations_per_region[dataset[-4:]] = (\n",
    "            datasets[dataset].groupby(\"REGION\")[\"STATION_NAME\"].nunique()\n",
    "        )\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "print(tabulate(pd.concat(stations_per_region, axis=1), headers=\"keys\", tablefmt=\"psql\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsetting study data\n",
    "Vancouver Island stations to study:\n",
    "\n",
    "* Vancouver Clark Drive\n",
    "* Vancouver International Airport\n",
    "* Vancouver North Vancouver Mahon Park\n",
    "* Vancouver North Vancouver Second Narrows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = [\n",
    "    \"Vancouver Clark Drive\",\n",
    "    \"Vancouver International Airport #2\",\n",
    "    \"North Vancouver Mahon Park\",\n",
    "    \"North Vancouver Second Narrows\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All istations found for datasets: PM25_2016, PM25_2017, PM25_2018, PM25_2019, PM25_2020, PM25_2021.\n"
     ]
    }
   ],
   "source": [
    "not_founds = []\n",
    "for dataset in datasets_list:\n",
    "    for station in stations:\n",
    "        if station not in datasets[dataset][\"STATION_NAME\"].unique():\n",
    "            print(f\"{station} station not found in {dataset}\")\n",
    "            not_founds.append(station)\n",
    "if len(not_founds) == 0:\n",
    "    print(f\"All istations found for datasets: {', '.join(datasets_list)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vancouver Clark Drive: 57014\n",
      "Vancouver International Airport #2: 57014\n",
      "North Vancouver Mahon Park: 57014\n",
      "North Vancouver Second Narrows: 57014\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE_PST</th>\n",
       "      <th>Vancouver_Clark_Drive_PM25</th>\n",
       "      <th>Vancouver_International_Airport_#2_PM25</th>\n",
       "      <th>North_Vancouver_Mahon_Park_PM25</th>\n",
       "      <th>North_Vancouver_Second_Narrows_PM25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01 01:00:00</td>\n",
       "      <td>30.557</td>\n",
       "      <td>22.71692</td>\n",
       "      <td>22.798870</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-01 02:00:00</td>\n",
       "      <td>34.661</td>\n",
       "      <td>21.95020</td>\n",
       "      <td>22.909090</td>\n",
       "      <td>6.341111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-01 03:00:00</td>\n",
       "      <td>35.419</td>\n",
       "      <td>21.25953</td>\n",
       "      <td>19.857730</td>\n",
       "      <td>5.340278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-01 04:00:00</td>\n",
       "      <td>24.335</td>\n",
       "      <td>19.93333</td>\n",
       "      <td>13.575990</td>\n",
       "      <td>3.907917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01 05:00:00</td>\n",
       "      <td>29.336</td>\n",
       "      <td>19.07922</td>\n",
       "      <td>7.079589</td>\n",
       "      <td>7.235889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             DATE_PST  Vancouver_Clark_Drive_PM25  \\\n",
       "0 2016-01-01 01:00:00                      30.557   \n",
       "1 2016-01-01 02:00:00                      34.661   \n",
       "2 2016-01-01 03:00:00                      35.419   \n",
       "3 2016-01-01 04:00:00                      24.335   \n",
       "4 2016-01-01 05:00:00                      29.336   \n",
       "\n",
       "   Vancouver_International_Airport_#2_PM25  North_Vancouver_Mahon_Park_PM25  \\\n",
       "0                                 22.71692                        22.798870   \n",
       "1                                 21.95020                        22.909090   \n",
       "2                                 21.25953                        19.857730   \n",
       "3                                 19.93333                        13.575990   \n",
       "4                                 19.07922                         7.079589   \n",
       "\n",
       "   North_Vancouver_Second_Narrows_PM25  \n",
       "0                                  NaN  \n",
       "1                             6.341111  \n",
       "2                             5.340278  \n",
       "3                             3.907917  \n",
       "4                             7.235889  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Asserting timeseries integrity and parallelism\n",
    "columns = [\"DATE_PST\", \"RAW_VALUE\"]\n",
    "starts, ends = [], []\n",
    "for dataset in datasets_list:\n",
    "    for station in stations:\n",
    "        subset = datasets[dataset][columns][\n",
    "            datasets[dataset][\"STATION_NAME\"] == station\n",
    "        ]\n",
    "        start = min(subset[\"DATE_PST\"])\n",
    "        end = max(subset[\"DATE_PST\"])\n",
    "        starts.append(start)\n",
    "        ends.append(end)\n",
    "        # Assert time series integrity\n",
    "        assert (\n",
    "            len(pd.date_range(start=start, end=end, freq=\"H\")) == subset.shape[0]\n",
    "        ), f\"{dataset}'s date range is incomplete or truncated.\"\n",
    "\n",
    "# Appending years and concatenating stations to a master dataframe\n",
    "master_df = {}\n",
    "master_df[\"DATE_PST\"] = pd.date_range(start=min(starts), end=max(ends), freq=\"H\")\n",
    "for station in stations:\n",
    "    first_df = 1\n",
    "    for dataset in datasets_list:\n",
    "        subset = datasets[dataset][columns][\n",
    "            datasets[dataset][\"STATION_NAME\"] == station\n",
    "        ]\n",
    "        if first_df:\n",
    "            pm25_complete = subset[\"RAW_VALUE\"]\n",
    "            first_df = 0\n",
    "        else:\n",
    "            pm25_complete = pd.concat(\n",
    "                [pm25_complete, subset[\"RAW_VALUE\"]], ignore_index=True\n",
    "            )\n",
    "    print(f\"{station}: {len(pm25_complete)}\")\n",
    "    master_df[station.replace(\" \", \"_\") + \"_PM25\"] = pm25_complete\n",
    "\n",
    "master_df = pd.DataFrame(master_df)\n",
    "master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 negative values found for Vancouver Clark Drive:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19874   -0.028597\n",
       "51793   -0.320931\n",
       "51794   -0.604097\n",
       "51795   -0.634181\n",
       "51796   -0.438903\n",
       "51800   -0.091346\n",
       "54003   -0.030625\n",
       "Name: Vancouver_Clark_Drive_PM25, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No negative values for Vancouver International Airport #2\n",
      "No negative values for North Vancouver Mahon Park\n",
      "No negative values for North Vancouver Second Narrows\n"
     ]
    }
   ],
   "source": [
    "# Screening for negative values\n",
    "for station in stations:\n",
    "    station_col = station.replace(\" \", \"_\") + \"_PM25\"\n",
    "    negatives = master_df[station_col][master_df[station_col] < 0]\n",
    "    if len(negatives):\n",
    "        print(f\"{len(negatives)} negative values found for {station}:\")\n",
    "        display(negatives)\n",
    "    else:\n",
    "        print(f\"No negative values for {station}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11187/2839988640.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  master_df[\"Vancouver_Clark_Drive_PM25\"][master_df[\"Vancouver_Clark_Drive_PM25\"] < 0] = math.nan\n"
     ]
    }
   ],
   "source": [
    "# Replacing negative values with NaN (missing)\n",
    "master_df[\"Vancouver_Clark_Drive_PM25\"][\n",
    "    master_df[\"Vancouver_Clark_Drive_PM25\"] < 0\n",
    "] = math.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No negative values for Vancouver Clark Drive\n",
      "No negative values for Vancouver International Airport #2\n",
      "No negative values for North Vancouver Mahon Park\n",
      "No negative values for North Vancouver Second Narrows\n"
     ]
    }
   ],
   "source": [
    "# Screening for negative values\n",
    "for station in stations:\n",
    "    station_col = station.replace(\" \", \"_\") + \"_PM25\"\n",
    "    negatives = master_df[station_col][master_df[station_col] < 0]\n",
    "    if len(negatives):\n",
    "        print(f\"{len(negatives)} negative values found for {station}:\")\n",
    "        display(negatives)\n",
    "    else:\n",
    "        print(f\"No negative values for {station}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.to_csv(\"data/2016_2021_master_df.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('air-we-breath')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a130129e68da027e0813cdf62beca0d5c82b3ac82c79cb680bc9be7e43ed81ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
